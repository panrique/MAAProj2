{"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.9"}},"nbformat_minor":5,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install numpy","metadata":{},"execution_count":null,"outputs":[],"id":"a802e8f7-26ee-4693-bec7-8985d62960ab"},{"cell_type":"code","source":"!pip install pandas","metadata":{},"execution_count":null,"outputs":[],"id":"b47a5f3e-d52d-474c-86c4-313fb1bcd778"},{"cell_type":"code","source":"!pip install scikit-learn","metadata":{},"execution_count":null,"outputs":[],"id":"fea9d704-1e25-4115-bf94-3b90bcb581e0"},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.metrics import mutual_info_score, accuracy_score, precision_score, recall_score, f1_score \nfrom sklearn.neighbors import KNeighborsClassifier\n\ndef calc_macro_recall(pred, label, classes):\n    t = 0\n    for c in classes:\n        # indices for \n        indices = np.where(label == c)\n    return t / classes.size\n\ndef calc_macro_precision(pred, label, classes):\n    return 1 / classes.size\n\ndef calc_macro_f1(pred, label, classes):\n    return 1 / classes.size\n\ndef mutual_information(x, y):\n    c_xy = np.histogram2d(x, y, bins=10)[0]\n    mi = mutual_info_score(None, None, contingency=c_xy)\n    return mi\n\ndef CLMax(X, y, k):\n    # Calculate the mutual information between each feature and the target variable\n    mi = np.zeros(X.shape[1])\n    for i in range(X.shape[1]):\n        mi[i] = mutual_information(X.iloc[:,i], y)\n    \n    # Rank the features based on their mutual information with the target variable\n    rank = np.argsort(-mi)\n    \n    # Select the top k features\n    selected_features = rank[:k]\n    \n    return selected_features\n\n\ndata = pd.read_csv(\"data/AcousticFeatures.csv\", delimiter=';')\n\ntrain_data = data.sample(frac=0.75, random_state=200)\ntest_data = data.drop(train_data.index)\nX_train = train_data.iloc[:, 1:]\nX_test = test_data.iloc[:, 1:]\ny_train = train_data.iloc[:, 0]\ny_test = test_data.iloc[:, 0]\n\n# Convert the target variable to a numeric form using label encoding\nle = LabelEncoder()\nclasses = np.unique(le.fit_transform(data.iloc[:, 0]))\ny_train = le.fit_transform(y_train)\ny_test = le.fit_transform(y_test)\n\n#3. and 4.\nselected_features25 = CLMax(X_train, y_train, k=25)\nselected_features15 = CLMax(X_train, y_train, k=15)\nX_train_selected25 = X_train.iloc[:, selected_features25]\nX_train_selected15 = X_train.iloc[:, selected_features15]\n\n#5.\n# Train a k-NN model using the selected features\nk = 5\nknn = KNeighborsClassifier(n_neighbors=k)\n#knn.fit(X_train_selected25, y_train)\nknn.fit(X_train_selected15, y_train)\n#y_pred = knn.predict(X_test.iloc[:, selected_features25])\ny_pred = knn.predict(X_test.iloc[:, selected_features15])\n        \n# Calculate the measures of performance\naccuracy = 1 - np.count_nonzero(y_pred - y_test) / len(y_test)\nmacro_recall = recall_score(y_test, y_pred, average='macro')\nmacro_precision = precision_score(y_test, y_pred, average='macro')\nmacro_f1 = f1_score(y_test, y_pred, average='macro')\n\nprint(\"accuracy_score:\", accuracy)\nprint(\"precision_score:\", macro_recall)\nprint(\"recall_score:\", macro_precision)\nprint(\"f1_score:\", macro_f1)\n","metadata":{"trusted":true},"execution_count":26,"outputs":[{"name":"stdout","text":"accuracy_score: 0.6\nprecision_score: 0.5815894746908071\nrecall_score: 0.5841927680162974\nf1_score: 0.5782554291117777\n","output_type":"stream"}],"id":"62f28ea4-2e98-422b-83ea-5ebe1cb4c9df"},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[],"id":"dce5fa32-1f76-47d9-951d-ba4688c3b18f"}]}