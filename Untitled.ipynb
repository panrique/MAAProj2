{"cells":[{"cell_type":"code","execution_count":null,"id":"a802e8f7-26ee-4693-bec7-8985d62960ab","metadata":{},"outputs":[],"source":["!pip install numpy"]},{"cell_type":"code","execution_count":null,"id":"b47a5f3e-d52d-474c-86c4-313fb1bcd778","metadata":{},"outputs":[],"source":["!pip install pandas"]},{"cell_type":"code","execution_count":null,"id":"fea9d704-1e25-4115-bf94-3b90bcb581e0","metadata":{},"outputs":[],"source":["!pip install scikit-learn"]},{"cell_type":"code","execution_count":26,"id":"62f28ea4-2e98-422b-83ea-5ebe1cb4c9df","metadata":{"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["accuracy_score: 0.6\n","precision_score: 0.5815894746908071\n","recall_score: 0.5841927680162974\n","f1_score: 0.5782554291117777\n"]}],"source":["import numpy as np\n","import pandas as pd\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.metrics import mutual_info_score, accuracy_score, precision_score, recall_score, f1_score \n","from sklearn.neighbors import KNeighborsClassifier\n","from scipy.special import softmax\n","from sklearn.linear_model import LogisticRegression\n","from scipy.stats import norm\n","from sklearn.preprocessing import StandardScaler\n","\n","# Define the model and approximation\n","def model(x, beta):\n","    # Multivariate Gaussian with mean and covariance parameters that depend on the selected features\n","    mu = np.dot(x, beta[1:])\n","    sigma = np.exp(beta[0])\n","    return np.random.normal(mu, sigma)\n","\n","def approx(x, tau, beta):\n","    # Multivariate Gaussian with mean and covariance parameters that depend on all the features\n","    mu = np.dot(x, beta[1:])\n","    sigma = np.exp(beta[0])\n","    return np.random.normal(mu, sigma)\n","\n","# Define the feature selection algorithm\n","def select_features(X, y, num_features):\n","    # Standardize the features\n","    scaler = StandardScaler()\n","    X_std = scaler.fit_transform(X)\n","\n","    # Initialize the selected features and the beta parameters\n","    selected_features = []\n","    beta = np.zeros(X.shape[1] + 1)\n","\n","    # Run the feature selection algorithm\n","    for k in range(num_features):\n","        # Compute the conditional likelihood for each feature\n","        conditional_likelihoods = np.zeros(X.shape[1])\n","        for j in range(X.shape[1]):\n","            if j not in selected_features:\n","                # Select the candidate feature to evaluate\n","                candidate_feature = np.hstack((X_std[:, selected_features], X_std[:, j][:, np.newaxis]))\n","                \n","                # Compute the conditional likelihood of the target variable given the selected features and the candidate feature\n","                conditional_likelihoods[j] = np.mean([np.log(model(candidate_feature[i], beta)) - np.log(approx(candidate_feature[i], X_std[:, selected_features], beta)) for i in range(X.shape[0]) if y[i] == y_train.values[0]])\n","\n","        # Select the feature with the highest conditional likelihood\n","        best_feature = np.argmax(conditional_likelihoods)\n","        selected_features.append(best_feature)\n","\n","        # Fit the model with the selected features\n","        X_selected = X_std[:, selected_features]\n","        X_selected[:, 0] = 1.0 # Add a constant term to the model\n","        beta = np.linalg.lstsq(X_selected, y, rcond=None)[0]\n","\n","    return selected_features\n","\n","def empirical_distributions(X, y):\n","    n_samples, n_features = X.shape\n","    C = len(np.unique(y))\n","    emp_dists = np.zeros((n_features, C), dtype=object)\n","    for c in range(C):\n","        X_c = X[y == c]\n","        for i in range(n_features):\n","            emp_dists[i, c] = norm(loc=np.mean(X_c[:, i]), scale=np.std(X_c[:, i]))\n","    return emp_dists\n","\n","def conditional_likelihood(emp_dists, X):\n","    n_samples, n_features = X.shape\n","    C = emp_dists.shape[1]\n","    p = np.zeros((n_features, C))\n","    for c in range(C):\n","        for i in range(n_features):\n","            p[i, c] = np.mean(emp_dists[i, c].pdf(X[:, i]))\n","    return p\n","\n","def conditional_mutual_information(p, y):\n","    n_samples = y.shape[0]\n","    C = len(np.unique(y))\n","    mi = np.zeros(p.shape[0])\n","    for i in range(p.shape[0]):\n","        for c in range(C):\n","            mi[i] += np.sum(p[i, c] * np.log(p[i, c] / np.mean(p[i, c])))\n","        mi[i] *= np.sum(p[i, :]) / n_samples\n","    return mi\n","\n","def feature_selection(X, y, K):\n","    emp_dists = empirical_distributions(X, y)\n","    p = conditional_likelihood(emp_dists, X)\n","    mi = conditional_mutual_information(p, y)\n","    idx = np.argsort(mi)[::-1][:K]\n","    return idx\n","\n","\n","\n","def select_features(X_train, y_train, k=25):\n","    # Initialize logistic regression model\n","    model = LogisticRegression(penalty=None, solver='lbfgs', multi_class='multinomial', max_iter=1000)\n","\n","    # Loop over each feature and compute its score\n","    scores = []\n","    for j in range(X_train.shape[1]):\n","        # Select all features except for j\n","        X_sel = X_train.drop(X_train.columns[j], axis=1)\n","        # Fit the model and compute conditional probabilities\n","        model.fit(X_sel, y_train)\n","        probas = softmax(model.predict_log_proba(X_sel), axis=1)\n","        # Compute the conditional likelihood\n","        Lj = np.sum(np.log(probas[np.arange(len(y_train)), y_train]))\n","        # Compute the score as the negative of the conditional likelihood\n","        scores.append(-Lj)\n","\n","    # Select the top-k features with the highest scores\n","    selected_features = np.argsort(scores)[:k]\n","\n","    return selected_features\n","\n","def mutual_information(x, y):\n","    c_xy = np.histogram2d(x, y, bins=10)[0]\n","    mi = mutual_info_score(None, None, contingency=c_xy)\n","    return mi\n","\n","def CLMax(X, y, k):\n","    # Calculate the mutual information between each feature and the target variable\n","    mi = np.zeros(X.shape[1])\n","    for i in range(X.shape[1]):\n","        mi[i] = mutual_information(X.iloc[:,i], y)\n","    \n","    # Rank the features based on their mutual information with the target variable\n","    rank = np.argsort(-mi)\n","    \n","    # Select the top k features\n","    selected_features = rank[:k]\n","    \n","    return selected_features\n","\n","\n","data = pd.read_csv(\"data/AcousticFeatures.csv\", delimiter=';')\n","\n","train_data = data.sample(frac=0.75, random_state=200)\n","test_data = data.drop(train_data.index)\n","X_train = train_data.iloc[:, 1:]\n","X_test = test_data.iloc[:, 1:]\n","y_train = train_data.iloc[:, 0]\n","y_test = test_data.iloc[:, 0]\n","\n","# Convert the target variable to a numeric form using label encoding\n","le = LabelEncoder()\n","classes = np.unique(le.fit_transform(data.iloc[:, 0]))\n","y_train = le.fit_transform(y_train)\n","y_test = le.fit_transform(y_test)\n","\n","#3. and 4.\n","selected_features25 = CLMax(X_train, y_train, k=25)\n","selected_features15 = CLMax(X_train, y_train, k=15)\n","X_train_selected25 = X_train.iloc[:, selected_features25]\n","X_train_selected15 = X_train.iloc[:, selected_features15]\n","\n","#5.\n","# Train a k-NN model using the selected features\n","k = 5\n","knn = KNeighborsClassifier(n_neighbors=k)\n","#knn.fit(X_train_selected25, y_train)\n","knn.fit(X_train_selected15, y_train)\n","#y_pred = knn.predict(X_test.iloc[:, selected_features25])\n","y_pred = knn.predict(X_test.iloc[:, selected_features15])\n","        \n","# Calculate the measures of performance\n","accuracy = 1 - np.count_nonzero(y_pred - y_test) / len(y_test)\n","macro_recall = recall_score(y_test, y_pred, average='macro')\n","macro_precision = precision_score(y_test, y_pred, average='macro')\n","macro_f1 = f1_score(y_test, y_pred, average='macro')\n","\n","print(\"accuracy_score:\", accuracy)\n","print(\"precision_score:\", macro_recall)\n","print(\"recall_score:\", macro_precision)\n","print(\"f1_score:\", macro_f1)\n","\n","\n","\n","# Select the top 25 features\n","print(f'Selected features before: {selected_features25}')\n","print(f'Selected features before: {selected_features15}')\n","#selected_features25 = select_features(X_train, y_train, k=25)\n","#selected_features15 = select_features(X_train, y_train, k=15)\n","#X_train_selected25 = X_train.iloc[:, selected_features25]\n","#X_train_selected15 = X_train.iloc[:, selected_features15]\n","#print(f'Selected features: {selected_features25}')\n","#print(f'Selected features: {selected_features15}')\n","#knn.fit(X_train_selected25, y_train)\n","#y_pred = knn.predict(X_test.iloc[:, selected_features25])\n","#knn.fit(X_train_selected15, y_train)\n","#y_pred = knn.predict(X_test.iloc[:, selected_features15])\n","\n","#accuracy = 1 - np.count_nonzero(y_pred - y_test) / len(y_test)\n","#macro_recall = recall_score(y_test, y_pred, average='macro')\n","#macro_precision = precision_score(y_test, y_pred, average='macro')\n","#macro_f1 = f1_score(y_test, y_pred, average='macro')\n","\n","#print(\"accuracy_score:\", accuracy)\n","#print(\"precision_score:\", macro_recall)\n","#print(\"recall_score:\", macro_precision)\n","#print(\"f1_score:\", macro_f1)\n","\n","\n","\n","selected_features25 = feature_selection(X_train.values, y_train, 25)\n","selected_features15 = feature_selection(X_train.values, y_train, 15)\n","# Print the selected features\n","print(\"Selected features:\", selected_features25)\n","print(\"Selected features:\", selected_features15)\n","X_train_selected25 = X_train.iloc[:, selected_features25]\n","X_train_selected15 = X_train.iloc[:, selected_features15]\n","knn.fit(X_train_selected25, y_train)\n","y_pred = knn.predict(X_test.iloc[:, selected_features25])\n","knn.fit(X_train_selected15, y_train)\n","y_pred = knn.predict(X_test.iloc[:, selected_features15])\n","\n","accuracy = 1 - np.count_nonzero(y_pred - y_test) / len(y_test)\n","macro_recall = recall_score(y_test, y_pred, average='macro')\n","macro_precision = precision_score(y_test, y_pred, average='macro')\n","macro_f1 = f1_score(y_test, y_pred, average='macro')\n","\n","print(\"accuracy_score:\", accuracy)\n","print(\"precision_score:\", macro_recall)\n","print(\"recall_score:\", macro_precision)\n","print(\"f1_score:\", macro_f1)\n","\n","\n"]},{"cell_type":"code","execution_count":null,"id":"dce5fa32-1f76-47d9-951d-ba4688c3b18f","metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.9"}},"nbformat":4,"nbformat_minor":5}
